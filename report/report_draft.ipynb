{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimization\n",
    "\n",
    "### Group 3\n",
    "\n",
    "### Scientific Introduction\n",
    "\n",
    "#### Background and Algorithm\n",
    "\n",
    "The particle swarm optimization algorithm was first developed by James Kennedy and Russell Eberhart in 1995, who were inspired by the movement of schools of fish and flocks of birds. Computer simulations of the flocking behavior of animals are common in the field of artificial life and are often used for computer animations (Hu). Kennedy and Russell observed that in a group, these animals were able to utilize both their own knowledge as well as the group's knowledge in order to navigate (1995). The particle swarm optimization method uses this idea by iteratively moving particles across the search space toward a weighted average of their own best position and the group's best position (1995). The algorithm is given below (Poli Kennedy and Blackwell):\n",
    "\n",
    "1. Initialize a set of particles with random positions and velocities in the search space\n",
    "2. For each particle:\n",
    "    1. Evaluate the fitness function\n",
    "    2. Compare the current fitness value with the particle's best fitness value ($p_k^i$). If the current value is better, set $p_k^i$ equal to the current value.\n",
    "3. Find the particle with the best fitness value and set $p_k^g$ to be that value.\n",
    "4. For each particle:\n",
    "    1. Update the position and velocity of particle $i$ at iteration $k+1$ according to the equations:\n",
    "    $$x_{k+1}^i = x_k^i + v^i_{k+1} \\tag{1}$$\n",
    "    $$v_{k+1}^i = w_kv_k^i + c_1r_1(p_k^i-x_k^i)+c_2r_2(p_k^g-x_k^i) \\tag{2}$$\n",
    "        where $w_k$ is an inerta parameter, $c_1$ is a cognitive parameter, $c_2$ is a social parameter, and $r_1$ and $r_2$ are random numbers in (0,1)\n",
    "    2. Repeat until convergence\n",
    "\n",
    "The algorithm starts out with particles moving randomly around the search space, then in each iteration, takes note of each particle's best position and the best position in the group, updating the particles' movements to be in the average direction of these two points. The particles' personal best positions and the global best position are weighted by parameters $c_1$ and $c_2$, as well as random components $r_1$ and $r_2$. The general role of these parameters is to create a balance between exploration and exploitation. \"Exploration\" refers to the ability of the algorithm to test many different parts of the search space, while \"exploitation\" is the precision with which the algorithm is able to concentrate around an optimum (Trelea). A higher level of exploration means the algorithm is less likely to converge to a local optimum rather than a global one, while a higher level of exploitation means that the algorithm will converge more quickly, but it might be to a local optimum rather than a global one. The trade-off between these two features depends largely on the function being optimized.  \n",
    "\n",
    "#### Parameter Choice \n",
    "\n",
    "The purpose of the random components $r_1$ and $r_2$ is to slow convergence of the algorithm, thereby increasing the level of exploration. \n",
    "\n",
    "Trelea suggests that the best method for choosing parameters is to start with those that will allow the algorithm to converge quickly, and if it gives different solutions each time it is run, use parameters that will slow the convergence until the same result can be obtained consistently (2002). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
